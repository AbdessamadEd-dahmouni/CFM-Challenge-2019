{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CFM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hxjtUvK8xkZz",
        "colab_type": "code",
        "outputId": "4c008c49-34b7-4c7e-b95f-6baee4ca9c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, model_from_json, Model\n",
        "from keras.layers import LSTM, Dropout, Flatten, Dense, concatenate, Input\n",
        "from keras.optimizers import adam\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "seF3G1b4zTS9",
        "colab_type": "code",
        "outputId": "a9522ffb-e315-4534-da2c-dc6ec6e1e61c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/CFM/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y1IGGedAjHNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training phase:"
      ]
    },
    {
      "metadata": {
        "id": "BAQP43nSbPBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reading and preprocessing training data:"
      ]
    },
    {
      "metadata": {
        "id": "pzXsbET61fzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_trn = pd.read_csv(\"x_train.csv\", index_col=0)\n",
        "y_trn = pd.read_csv(\"y_train.csv\", index_col=0)\n",
        "#Preprocessing training data:\n",
        "x_trn['y'] = y_trn.end_of_day_return\n",
        "x_trn.sort_values(by=['date'],inplace=True)\n",
        "x_trn.set_index(['date', 'eqt_code'], inplace=True)\n",
        "x_trn.fillna(0.0,inplace=True)\n",
        "y_trn = x_trn['y'].values\n",
        "x_trn.drop(['y'],axis=1,inplace=True)\n",
        "idx = x_trn.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gV0vt3TtbcRJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating features per stock:"
      ]
    },
    {
      "metadata": {
        "id": "xjOs9_a7DUcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3bd0e78-9a4d-45c2-99c7-cc20f0291a70"
      },
      "cell_type": "code",
      "source": [
        "#Features per stock \n",
        "std    = pd.DataFrame(x_trn.sum(axis=1).std(level = 'eqt_code'),   columns=['std']).reindex(index=idx, level=1)\n",
        "mean   = pd.DataFrame(x_trn.sum(axis=1).mean(level = 'eqt_code'),  columns = ['mean']).reindex(index=idx, level=1)\n",
        "median = pd.DataFrame(x_trn.sum(axis=1).median(level = 'eqt_code'),columns = ['median']).reindex(index=idx, level=1)\n",
        "#skew   = pd.DataFrame(x_trn.sum(axis=1).skew(level = 'eqt_code'),  columns=['skew']).reindex(index=idx, level=1)\n",
        "#kurt   = pd.DataFrame(x_trn.sum(axis=1).kurt(level = 'eqt_code'),  columns=['kurt']).reindex(index=idx, level=1)\n",
        "nx_train =    x_trn.join(mean,  how='inner')\n",
        "nx_train = nx_train.join(std,   how='inner')\n",
        "nx_train = nx_train.join(median,how='inner')\n",
        "#nx_train = nx_train.join(skew,  how='inner')\n",
        "#nx_train = nx_train.join(kurt,  how='inner')\n",
        "nx_train['scaled'] = (nx_train.iloc[:,:-5].sum(axis=1).sub(nx_train['median'])).divide(nx_train['std'])\n",
        "nx_train = nx_train[['mean','std','median','scaled']]\n",
        "nx_train = nx_train.reindex(idx,copy=True)\n",
        "X_st = nx_train.as_matrix()\n",
        "del std, mean, median,nx_train; gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "O4yCwsQqbh03",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalizing data:"
      ]
    },
    {
      "metadata": {
        "id": "uGkTXDDiea-4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Normalization\n",
        "# norms = (1/np.sqrt(x_trn.shape[1]))*x_trn.apply(lambda x: np.sqrt(x.dot(x)), axis=1)\n",
        "# x_trn = x_trn.divide(norms,axis=0)\n",
        "# y_trn = y_train/norms\n",
        "# x_trn.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nCQsYAMDbyMk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating time series features:"
      ]
    },
    {
      "metadata": {
        "id": "X61N1xKW30M7",
        "colab_type": "code",
        "outputId": "bd8c6acb-f819-401d-e359-42de015aa6a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "#Times series features\n",
        "#Rolling exp average\n",
        "X_ts = x_trn.as_matrix()[...,None]\n",
        "X_ts = np.concatenate((X_ts, x_trn.ewm(halflife=3.0,axis=1).mean().as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling exp average added')\n",
        "#Rolling min\n",
        "X_ts = np.concatenate((X_ts, x_trn.rolling(6,axis=1,min_periods=0).min().as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling min added')\n",
        "#Rolling max\n",
        "X_ts = np.concatenate((X_ts, x_trn.rolling(6,axis=1,min_periods=0).max().as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling max added')\n",
        "#Rolling median\n",
        "X_ts = np.concatenate((X_ts, x_trn.rolling(12,axis=1,min_periods=3).median().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling median added')\n",
        "#Rolling std\n",
        "X_ts = np.concatenate((X_ts, x_trn.rolling(12,axis=1,min_periods=3).std().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling std added')\n",
        "# #Rolling skew\n",
        "# X_ts = np.concatenate((X_ts, x_trn.rolling(12,axis=1,min_periods=3).skew().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "# print('Rolling skew added')\n",
        "# #Rolling kurt\n",
        "# X_ts = np.concatenate((X_ts, x_trn.rolling(12,axis=1,min_periods=3).kurt().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "# print('Rolling kurt added')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rolling exp average added\n",
            "Rolling min added\n",
            "Rolling max added\n",
            "Rolling median added\n",
            "Rolling std added\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C9XLpCB8b3bn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving features of training data:"
      ]
    },
    {
      "metadata": {
        "id": "G5DJkKW3dK3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save('X_series_features.npy',X_ts,allow_pickle=False)\n",
        "np.save('X_stocks_features.npy',X_st,allow_pickle=False)\n",
        "np.save('Y.npy',y_trn,allow_pickle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwbvuNVDMORu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run only if environment disconnects on google colab\n",
        "if 'X_ts' not in globals():\n",
        "  X_ts = np.load('X_series_features.npy',allow_pickle=False)\n",
        "if 'X_st' not in globals():\n",
        "  X_st = np.load('X_stocks_features.npy',allow_pickle=False)\n",
        "if 'y_trn' not in globals():\n",
        "  y_trn = np.load('Y.npy',allow_pickle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "quKduCsBcWfJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Custom loss metrics and accuracy for keras backend:"
      ]
    },
    {
      "metadata": {
        "id": "H9INnYxi3qZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def sign_acc(y_true, y_pred):\n",
        "    _c = y_pred * y_true\n",
        "    _c[_c<0] = 0\n",
        "    _c[_c>0] = 1\n",
        "    return np.mean(_c)\n",
        "  \n",
        "def K_acc(y_true, y_pred):\n",
        "    return K.mean(K.greater(y_pred*y_true, 0), axis=-1)\n",
        "  \n",
        "def K_loss(y_true, y_pred):\n",
        "  return K.mean(K.log(1. + K.exp(- y_true * y_pred)), axis=-1)\n",
        "\n",
        "def M_loss(y_pred, y_true):\n",
        "  return K.mean(K.maximum(0.3-y_pred*y_true,0.), axis=-1)\n",
        "\n",
        "def CFM_metric(y_true, y_pred):\n",
        "  return ((y_true > 0) == (y_pred > 0.5)).mean()\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4OIgAbicgtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training and validation split:"
      ]
    },
    {
      "metadata": {
        "id": "0cNPcZ3q3rf0",
        "colab_type": "code",
        "outputId": "05b66078-c720-4a99-f92a-efe270041751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "with_val= False\n",
        "if with_val:\n",
        "  #training-validation split\n",
        "  n = int(X_ts.shape[0]*.80)\n",
        "  X_ts_trn, X_ts_val = X_ts[:n], X_ts[n:]\n",
        "  X_st_trn, X_st_val = X_st[:n], X_st[n:]\n",
        "  Y_trn, Y_val = y_trn[:n], y_trn[n:]\n",
        "\n",
        "  del X_ts, X_st,x_trn, y_trn; gc.collect()\n",
        "else:\n",
        "  del x_trn;gc.collect()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "440"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "uq8nn7zLcmjR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Building the model: LSTM on time series features added features by stock"
      ]
    },
    {
      "metadata": {
        "id": "7w6VZo8pyGq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "def build_model(X_ts_trn, X_st_trn, Y_trn, model_name, with_val = False, val_data=None):\n",
        "  #, X_ts_val, X_st_val,Y_val,\n",
        "\t# define parameters\n",
        "  verbose, epochs, batch_size = 0, 30, 2000\n",
        "  # define model\n",
        "  features_ts = Input(shape=(X_ts_trn.shape[1], X_ts_trn.shape[2]), name='features_ts')\n",
        "  features_st = Input(shape=(X_st_trn.shape[1],), name='features_st')\n",
        "  lstm = Sequential()\n",
        "  lstm.add(LSTM(144,input_shape=(X_ts_trn.shape[1], X_ts_trn.shape[2])))\n",
        "  lstm.add(Dropout(rate=0.2))\n",
        "  lstm.add(Dense(24))\n",
        "  lstm_output = lstm(features_ts)\n",
        "  merged = concatenate([lstm_output,features_st],axis=1)\n",
        "  layer1 = Dense(15, activation='relu')(merged)\n",
        "  layer2 = Dropout(rate=0.2)(layer1)\n",
        "  layer3 = Dense(15, activation='relu')(layer2)\n",
        "  final  = Dense(1)(layer3)\n",
        "  model = Model(inputs=[features_ts, features_st], outputs=[final])\n",
        "  model.compile(loss= 'mae', optimizer='adam',metrics=[K_acc])\n",
        "  if with_val:\n",
        "    checkpointer = ModelCheckpoint(filepath='models/'+model_name+'_best_w.hdf5', monitor='val_K_acc' , verbose=1, save_best_only=True)\n",
        "    # fit network\n",
        "    hist = model.fit([X_ts_trn,X_st_trn], Y_trn, epochs=epochs, batch_size=batch_size, \n",
        "                   validation_data=val_data,\n",
        "                   callbacks=[checkpointer])\n",
        "  else:\n",
        "    checkpointer = ModelCheckpoint(filepath='models/'+model_name+'_best_w.hdf5', monitor='K_acc' , verbose=1, save_best_only=True)\n",
        "    # fit network\n",
        "    hist = model.fit([X_ts_trn,X_st_trn], Y_trn, epochs=epochs, batch_size=batch_size, \n",
        "                   callbacks=[checkpointer])\n",
        "  return model, hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ioPFTfIBc4Q1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the model:"
      ]
    },
    {
      "metadata": {
        "id": "GpuFE0U_yCDL",
        "colab_type": "code",
        "outputId": "56fae17e-3770-430f-f261-03b1839ef224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2150
        }
      },
      "cell_type": "code",
      "source": [
        "model_name = 'LSTM_mae_all'\n",
        "if with_val : \n",
        "  #train on (train, val) split of training data\n",
        "  model, hist = build_model(X_ts_trn, X_st_trn, Y_trn, model_name, True, ([X_ts_val, X_st_val], Y_val))\n",
        "else:\n",
        "  #train on whole data\n",
        "  model, hist = build_model(X_ts, X_st, y_trn, model_name)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "745327/745327 [==============================] - 114s 152us/step - loss: 0.7057 - K_acc: 0.5026\n",
            "\n",
            "Epoch 00001: K_acc improved from -inf to 0.50261, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 2/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7030 - K_acc: 0.5108\n",
            "\n",
            "Epoch 00002: K_acc improved from 0.50261 to 0.51081, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 3/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7026 - K_acc: 0.5156\n",
            "\n",
            "Epoch 00003: K_acc improved from 0.51081 to 0.51564, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 4/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7024 - K_acc: 0.5181\n",
            "\n",
            "Epoch 00004: K_acc improved from 0.51564 to 0.51807, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 5/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7022 - K_acc: 0.5201\n",
            "\n",
            "Epoch 00005: K_acc improved from 0.51807 to 0.52012, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 6/30\n",
            "745327/745327 [==============================] - 111s 149us/step - loss: 0.7022 - K_acc: 0.5208\n",
            "\n",
            "Epoch 00006: K_acc improved from 0.52012 to 0.52077, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 7/30\n",
            "745327/745327 [==============================] - 111s 149us/step - loss: 0.7021 - K_acc: 0.5199\n",
            "\n",
            "Epoch 00007: K_acc did not improve from 0.52077\n",
            "Epoch 8/30\n",
            "745327/745327 [==============================] - 111s 149us/step - loss: 0.7022 - K_acc: 0.5177\n",
            "\n",
            "Epoch 00008: K_acc did not improve from 0.52077\n",
            "Epoch 9/30\n",
            "745327/745327 [==============================] - 111s 149us/step - loss: 0.7021 - K_acc: 0.5209\n",
            "\n",
            "Epoch 00009: K_acc improved from 0.52077 to 0.52088, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 10/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7020 - K_acc: 0.5213\n",
            "\n",
            "Epoch 00010: K_acc improved from 0.52088 to 0.52131, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 11/30\n",
            "745327/745327 [==============================] - 111s 150us/step - loss: 0.7020 - K_acc: 0.5212\n",
            "\n",
            "Epoch 00011: K_acc did not improve from 0.52131\n",
            "Epoch 12/30\n",
            "745327/745327 [==============================] - 111s 149us/step - loss: 0.7019 - K_acc: 0.5218\n",
            "\n",
            "Epoch 00012: K_acc improved from 0.52131 to 0.52178, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 13/30\n",
            "745327/745327 [==============================] - 111s 149us/step - loss: 0.7019 - K_acc: 0.5217\n",
            "\n",
            "Epoch 00013: K_acc did not improve from 0.52178\n",
            "Epoch 14/30\n",
            "745327/745327 [==============================] - 111s 149us/step - loss: 0.7019 - K_acc: 0.5219\n",
            "\n",
            "Epoch 00014: K_acc improved from 0.52178 to 0.52192, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 15/30\n",
            "745327/745327 [==============================] - 111s 150us/step - loss: 0.7018 - K_acc: 0.5220\n",
            "\n",
            "Epoch 00015: K_acc improved from 0.52192 to 0.52198, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 16/30\n",
            "745327/745327 [==============================] - 113s 152us/step - loss: 0.7018 - K_acc: 0.5218\n",
            "\n",
            "Epoch 00016: K_acc did not improve from 0.52198\n",
            "Epoch 17/30\n",
            "745327/745327 [==============================] - 112s 151us/step - loss: 0.7018 - K_acc: 0.5220\n",
            "\n",
            "Epoch 00017: K_acc improved from 0.52198 to 0.52204, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 18/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7018 - K_acc: 0.5215\n",
            "\n",
            "Epoch 00018: K_acc did not improve from 0.52204\n",
            "Epoch 19/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7017 - K_acc: 0.5221\n",
            "\n",
            "Epoch 00019: K_acc improved from 0.52204 to 0.52210, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 20/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7017 - K_acc: 0.5220\n",
            "\n",
            "Epoch 00020: K_acc did not improve from 0.52210\n",
            "Epoch 21/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7017 - K_acc: 0.5217\n",
            "\n",
            "Epoch 00021: K_acc did not improve from 0.52210\n",
            "Epoch 22/30\n",
            "745327/745327 [==============================] - 113s 152us/step - loss: 0.7016 - K_acc: 0.5228\n",
            "\n",
            "Epoch 00022: K_acc improved from 0.52210 to 0.52279, saving model to models/features_w_mae_all.hdf5\n",
            "Epoch 23/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7016 - K_acc: 0.5221\n",
            "\n",
            "Epoch 00023: K_acc did not improve from 0.52279\n",
            "Epoch 24/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7016 - K_acc: 0.5222\n",
            "\n",
            "Epoch 00024: K_acc did not improve from 0.52279\n",
            "Epoch 25/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7015 - K_acc: 0.5221\n",
            "\n",
            "Epoch 00025: K_acc did not improve from 0.52279\n",
            "Epoch 26/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7014 - K_acc: 0.5220\n",
            "\n",
            "Epoch 00026: K_acc did not improve from 0.52279\n",
            "Epoch 27/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7014 - K_acc: 0.5224\n",
            "\n",
            "Epoch 00027: K_acc did not improve from 0.52279\n",
            "Epoch 28/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7014 - K_acc: 0.5218\n",
            "\n",
            "Epoch 00028: K_acc did not improve from 0.52279\n",
            "Epoch 29/30\n",
            "745327/745327 [==============================] - 112s 150us/step - loss: 0.7014 - K_acc: 0.5226\n",
            "\n",
            "Epoch 00029: K_acc did not improve from 0.52279\n",
            "Epoch 30/30\n",
            "745327/745327 [==============================] - 112s 151us/step - loss: 0.7013 - K_acc: 0.5220\n",
            "\n",
            "Epoch 00030: K_acc did not improve from 0.52279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "31fjL5MPbHtP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving the model and its weights:"
      ]
    },
    {
      "metadata": {
        "id": "V3K9cRsQnn21",
        "colab_type": "code",
        "outputId": "eda4bc05-fb67-4cfb-ce3c-f25687fa772f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open('models/'+model_name+'.json', 'w') as json_file:\n",
        "  json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights('models/'+model_name+'_last_w.hdf5')\n",
        "print('Saved model'+model_name'+ to disk')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model LSTM to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "II-oFG-Skqnq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot of training and validation loss"
      ]
    },
    {
      "metadata": {
        "id": "poFDq2G-kGSr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if with_val:\n",
        "fig,ax=plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
        "  ax[0].plot(hist.history['loss'])\n",
        "  ax[0].set_xlabel('epoch')\n",
        "  ax[0].set_ylabel('loss')\n",
        "  ax[0].set_title('model train loss')\n",
        "  ax[0].legend(['train'], loc='upper left')\n",
        "\n",
        "  ax[1].plot(hist.history['val_loss'])\n",
        "  ax[1].set_xlabel('epoch')\n",
        "  ax[1].set_ylabel('val_loss')\n",
        "  ax[1].set_title('model validation loss')\n",
        "  ax[1].legend(['val'], loc='upper left')\n",
        "  fig.suptitle(model_name)\n",
        "  plt.show()\n",
        "  fig.savefig(model_name+'.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hX-XZPDBjixQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test phase:"
      ]
    },
    {
      "metadata": {
        "id": "k6YJwxXXdFPY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Deleting training data from memory:"
      ]
    },
    {
      "metadata": {
        "id": "ErAEn8sPGtXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7422d2e9-3794-40bb-d3f0-bed3334d22c7"
      },
      "cell_type": "code",
      "source": [
        "del X_ts,X_st; gc.collect()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "msPvnzLmdL0x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reading test data and creating features:"
      ]
    },
    {
      "metadata": {
        "id": "EAfwVvG4-Rrq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_tst = pd.read_csv(\"x_test.csv\",  index_col=0)\n",
        "#Preprocessing test data:\n",
        "x_tst['index'] = x_tst.index\n",
        "idx_before = x_tst.index\n",
        "x_tst.sort_values(by=['date'],inplace=True)\n",
        "x_tst.set_index(['date', 'eqt_code'], inplace=True)\n",
        "x_tst.fillna(0.0,inplace=True)\n",
        "idx_tst = x_tst['index'].values\n",
        "x_tst.drop(['index'],axis=1,inplace=True)\n",
        "idx = x_tst.index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "goGlr4IX-0iH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d082e7a-975d-42d7-efda-60b5dc05b6df"
      },
      "cell_type": "code",
      "source": [
        "#Features per stock \n",
        "std    = pd.DataFrame(x_tst.sum(axis=1).std(level = 'eqt_code'),   columns=['std']).reindex(index=idx, level=1)\n",
        "mean   = pd.DataFrame(x_tst.sum(axis=1).mean(level = 'eqt_code'),  columns = ['mean']).reindex(index=idx, level=1)\n",
        "median = pd.DataFrame(x_tst.sum(axis=1).median(level = 'eqt_code'),columns = ['median']).reindex(index=idx, level=1)\n",
        "#skew   = pd.DataFrame(x_trn.sum(axis=1).skew(level = 'eqt_code'),  columns=['skew']).reindex(index=idx, level=1)\n",
        "#kurt   = pd.DataFrame(x_trn.sum(axis=1).kurt(level = 'eqt_code'),  columns=['kurt']).reindex(index=idx, level=1)\n",
        "nx_tst =  x_tst.join(mean,  how='inner')\n",
        "nx_tst = nx_tst.join(std,   how='inner')\n",
        "nx_tst = nx_tst.join(median,how='inner')\n",
        "#nx_train = nx_train.join(skew,  how='inner')\n",
        "#nx_train = nx_train.join(kurt,  how='inner')\n",
        "nx_tst['scaled'] = (nx_tst.iloc[:,:-5].sum(axis=1).sub(nx_tst['median'])).divide(nx_tst['std'])\n",
        "nx_tst = nx_tst[['mean','std','median','scaled']]\n",
        "nx_tst = nx_tst.reindex(idx,copy=True)\n",
        "X_st_tst = nx_tst.as_matrix()\n",
        "del std, mean, median,nx_tst; gc.collect()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "M-ZHzLyO_ceY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "5a8c5034-8459-44b7-c08f-d36ec76a1ba0"
      },
      "cell_type": "code",
      "source": [
        "#Times series features\n",
        "#Rolling exp average\n",
        "X_ts_tst = x_tst.as_matrix()[...,None]\n",
        "X_ts_tst = np.concatenate((X_ts_tst, x_tst.ewm(halflife=3.0,axis=1).mean().as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling exp average added')\n",
        "#Rolling min\n",
        "X_ts_tst = np.concatenate((X_ts_tst, x_tst.rolling(6,axis=1,min_periods=0).min().as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling min added')\n",
        "#Rolling max\n",
        "X_ts_tst = np.concatenate((X_ts_tst, x_tst.rolling(6,axis=1,min_periods=0).max().as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling max added')\n",
        "#Rolling median\n",
        "X_ts_tst = np.concatenate((X_ts_tst, x_tst.rolling(12,axis=1,min_periods=3).median().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling median added')\n",
        "#Rolling std\n",
        "X_ts_tst = np.concatenate((X_ts_tst, x_tst.rolling(12,axis=1,min_periods=3).std().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "print('Rolling std added')\n",
        "# #Rolling skew\n",
        "# X_ts = np.concatenate((X_ts, x_trn.rolling(12,axis=1,min_periods=3).skew().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "# print('Rolling skew added')\n",
        "# #Rolling kurt\n",
        "# X_ts = np.concatenate((X_ts, x_trn.rolling(12,axis=1,min_periods=3).kurt().ffill(axis=1).bfill(axis=1).as_matrix()[...,None]),axis=-1)\n",
        "# print('Rolling kurt added')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rolling exp average added\n",
            "Rolling min added\n",
            "Rolling max added\n",
            "Rolling median added\n",
            "Rolling std added\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KPpvmrHudziF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving features of test data:"
      ]
    },
    {
      "metadata": {
        "id": "UwR4K35rdyp5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save('X_series_features_test.npy',X_ts_tst,allow_pickle=False)\n",
        "np.save('X_stocks_features_test.npy',X_st_tst,allow_pickle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6YU9-5aeAGv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the saved model if necessary (if google colab disconnects):"
      ]
    },
    {
      "metadata": {
        "id": "7ZRz-Ww0n9Q7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_to_load = 'LSTM_mae_all'\n",
        "# load json and create model\n",
        "with open('models/'+model_to_load+'.json', 'r') as json_file:\n",
        "  loaded_model_json = json_file.read()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "# best or last weights:\n",
        "w_type = 'best'\n",
        "model.load_weights('models/'+model_to_load+'_'+w_type+'_w.hdf5')\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcYZNB89dZ99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Running the model on test data:"
      ]
    },
    {
      "metadata": {
        "id": "hDRV3h2HAK3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "caf03b2a-6b92-4ee1-d900-02dd35a579e9"
      },
      "cell_type": "code",
      "source": [
        "y_hat = model.predict([X_ts_tst, X_st_tst],batch_size=200,verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "319769/319769 [==============================] - 99s 308us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KJTiAD4Gdhzx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reordering and saving data:"
      ]
    },
    {
      "metadata": {
        "id": "WoYUL4znIBHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = pd.DataFrame(y_hat[:,0],columns=['end_of_day_return'])\n",
        "y_pred.index = idx_tst\n",
        "y_pred = y_pred.reindex(idx_before, copy=True)\n",
        "y_pred.to_csv(model_name+'.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}